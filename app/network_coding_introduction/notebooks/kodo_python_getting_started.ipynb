{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed under the \"STEINWURF RESEARCH LICENSE 1.0\".\n",
    "# See accompanying file LICENSE.rst or\n",
    "# http://www.steinwurf.com/license.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kodo-python Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the getting started ipython notebook for kodo-python.\n",
    "\n",
    "This guide is intended for newcomers to the Kodo library. The guide will in tiny steps guide you through the creation and usage of both encoders and decoders.\n",
    "Even though this guide focuses on the Python language bindings for Kodo - a similar API exists for other languages including C, C++, and Go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Kodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with Kodo-python, you obviously need to have it installed and available. To ensure that's the case, try importing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the import worked, you are ready to move on to the next step. Otherwise please (re)visit the README.rst of the kodo-python repository for installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In kodo, both encoders and decoders are created using factories. Doing so allows efficient memory management and reuse of various components and computations. \n",
    "\n",
    "Therefore, before creating an encoder, let's look at the encoder factories provided by the ``kodo`` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FulcrumEncoderFactory\n",
      "NoCodeEncoderFactory\n",
      "PerpetualEncoderFactory\n",
      "RLNCEncoderFactory\n"
     ]
    }
   ],
   "source": [
    "# print all members containing \"Factory\" and \"Encoder\"\n",
    "print(\"\\n\".join([item for item in dir(kodo) if all([keyword in item for keyword in [\"Factory\", \"Encoder\"]])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the output, many different encoder factories exist. Most of these have decoder factory counterparts.\n",
    "\n",
    "The factory names are, with some exceptions, a combination of the encoding algorithm and the underlying finite field.\n",
    "\n",
    "For this walkthrough we pick the full vector factory using the binary field, i.e. the **``FullVector``**``EncoderFactory``**``Binary``** factory.\n",
    "\n",
    "Note: *For this guide, any of the factories should work. For this reason I'll define the factory class as ``EncoderFactory``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the full vector binary encoder factory as EncoderFactory\n",
    "EncoderFactory = kodo.RLNCEncoderFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using python's ``help`` function, we can inspect the  ``EncoderFactory``'s constructor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on instancemethod in module kodo:\n",
      "\n",
      "__init__(...)\n",
      "    Factory constructor.\n",
      "    \n",
      "    :param field: The finite field to use.\n",
      "    :param symbols: The number of symbols in a block.\n",
      "    :param symbol_size: The size of a symbol in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get information about the encoder factory's __init__ function\n",
    "help(EncoderFactory.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the documentation, we can see that we need to provide the ``field``, ``symbols``, and ``symbol_size`` to create a factory.\n",
    "\n",
    "These parameters represent the size of the Galois field, the generation size and the packet size in our book chapter. The developers of Kodo, used a different notation to refer to these parameters.\n",
    "\n",
    "The proper values to pick depends on the use case, we'll pick the numbers 4 and 32 for the symbols and symbol_size, respectively.\n",
    "These numbers would be low for a real use case, but they serve us well for this example.\n",
    "\n",
    "Let's create an encoder_factory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = 4\n",
    "symbol_size = 32\n",
    "\n",
    "encoder_factory = EncoderFactory(\n",
    "    field = kodo.field.binary,\n",
    "    symbols=symbols,\n",
    "    symbol_size=symbol_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which methods are available for the encoder_factory, we can use python's ``dir`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\n",
      "set_coding_vector_format\n",
      "set_symbol_size\n",
      "set_symbols\n",
      "symbol_size\n",
      "symbols\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(encoder_factory) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``build`` method is used for creating encoders. Let's create an encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_factory.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic, we've build our first encoder! Let's see what we can use it for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size\n",
      "density\n",
      "generate\n",
      "in_systematic_phase\n",
      "is_systematic_on\n",
      "payload_size\n",
      "rank\n",
      "set_const_symbol\n",
      "set_const_symbols\n",
      "set_density\n",
      "set_seed\n",
      "set_systematic_off\n",
      "set_systematic_on\n",
      "set_trace_callback\n",
      "set_trace_off\n",
      "set_trace_stdout\n",
      "set_zone_prefix\n",
      "symbol_size\n",
      "symbols\n",
      "write_payload\n",
      "write_symbol\n",
      "write_uncoded_symbol\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(encoder) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us call a method on the encoder. Lets see what is the block size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block size: 128\n"
     ]
    }
   ],
   "source": [
    "block_size = encoder.block_size()\n",
    "print(\"Block size: {}\".format(block_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the maximum block size is derived from the previously set ``symbols`` and ``symbol_size``. The block size is the total ammount of data that the encoder encodes together. It is the generation size times the packet size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated max block size: 128\n"
     ]
    }
   ],
   "source": [
    "calculated_max_block_size = symbols * symbol_size\n",
    "print(\"Calculated max block size: {}\".format(calculated_max_block_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function called ``print_encoder_state`` to inspect the state of our newly created encoder. This function will take an encoder as an argument, will call some methods related to the state on the encoder, and will print the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_systematic_on: True\n",
      "in_systematic_phase: False\n",
      "payload_size: 39\n",
      "rank: 0\n",
      "symbol_size: 32\n",
      "symbols: 4\n"
     ]
    }
   ],
   "source": [
    "def print_encoder_state(encoder):\n",
    "    print(\n",
    "        \"block_size: {}\\n\"\n",
    "        \"is_systematic_on: {}\\n\"\n",
    "        \"in_systematic_phase: {}\\n\"\n",
    "        \"payload_size: {}\\n\"\n",
    "        \"rank: {}\\n\"\n",
    "        \"symbol_size: {}\\n\"\n",
    "        \"symbols: {}\".format(\n",
    "            encoder.block_size(),\n",
    "            encoder.is_systematic_on(),\n",
    "            encoder.in_systematic_phase(),\n",
    "            encoder.payload_size(),\n",
    "            encoder.rank(),\n",
    "            encoder.symbol_size(),\n",
    "            encoder.symbols())\n",
    "    )\n",
    "print_encoder_state(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ``write_payload`` method to encode the data, but since we have yet to tell encoder what data to encode, we can't use it yet.\n",
    "This can be seen from the encoder rank which is 0.\n",
    "\n",
    "Kodo uses python ``bytearrays`` as data objects.\n",
    "\n",
    "Let's create some data to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data string: 128\n"
     ]
    }
   ],
   "source": [
    "data_in = bytearray(\n",
    "    \"The size of this data is exactly 128 bytes \"\n",
    "    \"which means it will fit perfectly in a single generation. \"\n",
    "    \"That is very lucky, indeed!\",\n",
    "    'utf-8'\n",
    ")\n",
    "print(\"Length of data string: {}\".format(len(data_in)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tell the encoder the data to encode. Note that the user must take care of the lifetime of data_in. This bytearray must not go out of scope while the encoder exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_const_symbols(data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be able to see how the state of the encoder has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_systematic_on: True\n",
      "in_systematic_phase: True\n",
      "payload_size: 39\n",
      "rank: 4\n",
      "symbol_size: 32\n",
      "symbols: 4\n"
     ]
    }
   ],
   "source": [
    "print_encoder_state(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the rank is now equal to the number of symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_symbols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-09e7d401917f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_symbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'max_symbols' is not defined"
     ]
    }
   ],
   "source": [
    "encoder.rank() == symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only encode packets if the rank is ``> 0``.\n",
    "\n",
    "Let's encode some packets using the ``write_payload`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet1: bytearray(b'\\x02\\x00\\x00The size of this data is exactly')\n",
      "packet2: bytearray(b'\\x02\\x00\\x01 128 bytes which means it will f')\n",
      "packet3: bytearray(b'\\x02\\x00\\x02it perfectly in a single generat')\n",
      "packet4: bytearray(b'\\x02\\x00\\x03ion. That is very lucky, indeed!')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "packet1 = encoder.write_payload()\n",
    "packet2 = encoder.write_payload()\n",
    "packet3 = encoder.write_payload()\n",
    "packet4 = encoder.write_payload()\n",
    "\n",
    "print(\n",
    "    \"packet1: {}\\n\"\n",
    "    \"packet2: {}\\n\"\n",
    "    \"packet3: {}\\n\"\n",
    "    \"packet4: {}\\n\".format(\n",
    "        packet1,\n",
    "        packet2,\n",
    "        packet3,\n",
    "        packet4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all the packets are prefixed with ``'b'\\x02\\x00\\x0i`` where `i` goes from 0 to 3 - this is python displaying the packet header containing the symbol id. The symbol id's goes from 0 to 3 because our generation size is of four packets.\n",
    "\n",
    "The reason why the contents of the packets are readable is that the encoder is in systematic phase. Systematic means that the encoder keeps each symbol uncoded in the first iteration. During the systematic phase, instead of appending the encoding coefficients, the kodo encoder only appends the packet id as two bytes, and a byte ``\\x02`` to indicate another kodo object what type of encoder produced the packet. In this example, ``\\x02`` means an RLNC encoder in systematic phase.\n",
    "\n",
    "Because we've set the generation size to be four symbols, and we've created four packets - the encoder is no longer in systematic phase:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.in_systematic_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that any subsequent packets will be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet5: bytearray(b'\\x08\\x1c\\x81]TI^\\\\\\x16\\x006\\x11\\x15\\x11SI\\x04H\\x1f\\x06\\x1aYM\\t\\x14\\r\\x18YETI\\x19\\r\\t\\tDG')\n"
     ]
    }
   ],
   "source": [
    "packet5 = encoder.write_payload()\n",
    "print(\"packet5: {}\".format(packet5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the encoding is random, the data could still be uncoded, it will however most likely be unreadable. If the payload of the coded packet is readable, you can run the previous cell again, and see how the coded payload varies each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a decoder factory and a decoder so that we can decode our newly generated packets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_factory = kodo.RLNCDecoderFactory(kodo.field.binary, symbols, symbol_size)\n",
    "decoder = decoder_factory.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate which methods are available for the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size\n",
      "is_complete\n",
      "is_partially_complete\n",
      "is_status_updater_enabled\n",
      "is_symbol_missing\n",
      "is_symbol_partially_decoded\n",
      "is_symbol_pivot\n",
      "is_symbol_uncoded\n",
      "payload_size\n",
      "rank\n",
      "read_payload\n",
      "read_symbol\n",
      "read_uncoded_symbol\n",
      "set_mutable_symbol\n",
      "set_mutable_symbols\n",
      "set_seed\n",
      "set_status_updater_off\n",
      "set_status_updater_on\n",
      "set_trace_callback\n",
      "set_trace_off\n",
      "set_trace_stdout\n",
      "set_zone_prefix\n",
      "symbol_size\n",
      "symbols\n",
      "symbols_missing\n",
      "symbols_partially_decoded\n",
      "symbols_uncoded\n",
      "update_symbol_status\n",
      "write_payload\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(decoder) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder and decoder share a few methods. Most of these shared methods have the same meaning.\n",
    "\n",
    "Let's create a function to inspect the state of our newly created decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_complete: False\n",
      "payload_size: 39\n",
      "rank: 0\n",
      "symbol_size: 32\n",
      "symbols: 4\n",
      "symbols_uncoded: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_decoder_state(decoder):\n",
    "    print(\n",
    "        \"block_size: {}\\n\"\n",
    "        \"is_complete: {}\\n\"\n",
    "        \"payload_size: {}\\n\"\n",
    "        \"rank: {}\\n\"\n",
    "        \"symbol_size: {}\\n\"\n",
    "        \"symbols: {}\\n\"\n",
    "        \"symbols_uncoded: {}\\n\".format(\n",
    "            decoder.block_size(),\n",
    "            decoder.is_complete(),\n",
    "            decoder.payload_size(),\n",
    "            decoder.rank(),\n",
    "            decoder.symbol_size(),\n",
    "            decoder.symbols(),\n",
    "            decoder.symbols_uncoded())\n",
    "    )\n",
    "print_decoder_state(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's probably the most interesting thing here is the rank. The rank corresponds to the number of innovative packets received.\n",
    "\n",
    "As we did with the encoder, we should provide the decoder with a data object of type bytearray to store the received data. Lets call this object ``data_out``. The size of this object is the size of the ``block_size`` of the decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = bytearray(decoder.block_size())\n",
    "decoder.set_mutable_symbols(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we read one of our previously generated packets, we should see the rank increase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.read_payload(packet1)\n",
    "decoder.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it does.\n",
    "\n",
    "We can now try to read the 5th packet, and see what it does to the state. The unique thing about the 5th packet, is that it's the only one which has been encoded, due to our encoder being systematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_complete: False\n",
      "payload_size: 39\n",
      "rank: 2\n",
      "symbol_size: 32\n",
      "symbols: 4\n",
      "symbols_uncoded: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder.read_payload(packet5)\n",
    "print_decoder_state(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank has increased to 2! This means that we've read two (innovative) packets. If we print the current data in the decoder we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The size of this data is exactlyI^\\\\\\x16_6\\x11\\x15\\x11SI\\x04H\\x1f\\x06\\x1aYM\\t\\x14\\r\\x18YETI\\x19\\r\\t\\tDG________________________________________________________________'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.decode('utf-8').replace('\\x00', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first part of the string is readable. Depending on the encoding of the 5th packet other parts of the string may or may not be readable. The empty bytes of the data are printed as ``_``.\n",
    "\n",
    "If we feed the same packet(s) to the decoder multiple times we will not increase its rank - no matter how many times we do so. We are simply feeding the decoder with linear dependent packets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank after rereading packet1: 2\n",
      "Rank after rereading packet5: 2\n",
      "Rank after rereading 100 times: 2\n"
     ]
    }
   ],
   "source": [
    "# Once\n",
    "decoder.read_payload(packet1)\n",
    "print(\"Rank after rereading packet1: {}\".format(decoder.rank()))\n",
    "decoder.read_payload(packet5)\n",
    "print(\"Rank after rereading packet5: {}\".format(decoder.rank()))\n",
    "\n",
    "# A 100 times\n",
    "for i in range(100):\n",
    "    decoder.read_payload(packet1)\n",
    "    decoder.read_payload(packet5)\n",
    "\n",
    "print(\"Rank after rereading 100 times: {}\".format(decoder.rank()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the data we feed the decoder is not innovative.\n",
    "\n",
    "Note that the rank may only increase by one when reading a packet.\n",
    "\n",
    "If we start feeding the decoder new coded data, we will at one point have a complete decoded generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "while not decoder.is_complete():\n",
    "    decoder.read_payload(encoder.write_payload())\n",
    "    print(decoder.rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And when the decoding is complete we should be able to extract the whole string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'The size of this data is exactly 128 bytes which means it will fit perfectly in a single generation. That is very lucky, indeed!')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_out)\n",
    "data_out == data_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray, it worked!\n",
    "\n",
    "For more information and inspiration please look through some of the many examples of the kodo-python library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
